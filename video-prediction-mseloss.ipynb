{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing libraries","metadata":{"id":"BT6Pj6S7eopf"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nfrom skimage.metrics import structural_similarity as ssim\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms","metadata":{"id":"BrRaFGpx4e6U","execution":{"iopub.status.busy":"2021-12-13T17:38:27.158835Z","iopub.execute_input":"2021-12-13T17:38:27.159323Z","iopub.status.idle":"2021-12-13T17:38:29.438488Z","shell.execute_reply.started":"2021-12-13T17:38:27.159284Z","shell.execute_reply":"2021-12-13T17:38:29.437662Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Data Loading\n\n#### Working with ucf101 dataset\n\n","metadata":{"id":"YPiNBWeKeSiF"}},{"cell_type":"code","source":"# Download dataset \n\n!wget -q https://git.io/JGc31 -O ucf101_top5.tar.gz\n!tar xf ucf101_top5.tar.gz","metadata":{"id":"XUHj1btneSWq","execution":{"iopub.status.busy":"2021-12-13T17:38:29.440384Z","iopub.execute_input":"2021-12-13T17:38:29.440889Z","iopub.status.idle":"2021-12-13T17:39:40.796440Z","shell.execute_reply.started":"2021-12-13T17:38:29.440850Z","shell.execute_reply":"2021-12-13T17:39:40.795407Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_path = './train'\ntest_path = './test'","metadata":{"id":"wlswHpoBefJh","execution":{"iopub.status.busy":"2021-12-13T17:39:40.798289Z","iopub.execute_input":"2021-12-13T17:39:40.798584Z","iopub.status.idle":"2021-12-13T17:39:40.805119Z","shell.execute_reply.started":"2021-12-13T17:39:40.798539Z","shell.execute_reply":"2021-12-13T17:39:40.804239Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_files = os.listdir(train_path)\nrandom.shuffle(train_files)\ntrain_files = train_files[:200]\nprint('Number of vidoes in train dir: {}'.format(len(train_files)))\nprint(train_files[:10])   # first 10 videos in train dir","metadata":{"id":"ZH1mrCSrejEf","outputId":"b8cca04e-cb7b-43d0-b236-deab5b88359a","execution":{"iopub.status.busy":"2021-12-13T17:39:40.807938Z","iopub.execute_input":"2021-12-13T17:39:40.808214Z","iopub.status.idle":"2021-12-13T17:39:40.817017Z","shell.execute_reply.started":"2021-12-13T17:39:40.808180Z","shell.execute_reply":"2021-12-13T17:39:40.816343Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_files = os.listdir(test_path)\nprint('Number of vidoes in test dir: {}'.format(len(test_files)))\nprint(test_files[:10])  # first 10 videos in test dir","metadata":{"id":"-QQf9oOYfCdp","outputId":"7f401323-7280-4f35-dac9-a9f2ea2506fd","execution":{"iopub.status.busy":"2021-12-13T17:39:40.818241Z","iopub.execute_input":"2021-12-13T17:39:40.818566Z","iopub.status.idle":"2021-12-13T17:39:40.825175Z","shell.execute_reply.started":"2021-12-13T17:39:40.818485Z","shell.execute_reply":"2021-12-13T17:39:40.824308Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Utilities","metadata":{"id":"6qrLnlQONJuP"}},{"cell_type":"code","source":"def trace(x, var):\n  print(\"Shape of {}: {}\".format(var , x.shape))\n\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Validation loss decreased. Saving checkpoint...\")\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\ndef plot_loss(train_loss, val_loss, save_fig=False):\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(\"Loss\")\n  plt.plot(train_loss, label='Train Loss')\n  plt.plot(val_loss, label='Val Loss')\n  plt.legend()\n  plt.title('Train loss vs Validation Loss')\n  plt.savefig('loss.png')\n  plt.show()","metadata":{"id":"qLzSj81hNI3U","execution":{"iopub.status.busy":"2021-12-13T17:39:40.826483Z","iopub.execute_input":"2021-12-13T17:39:40.826926Z","iopub.status.idle":"2021-12-13T17:39:40.836093Z","shell.execute_reply.started":"2021-12-13T17:39:40.826877Z","shell.execute_reply":"2021-12-13T17:39:40.835416Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nMAX_FRAMES = 20\nIMG_SIZE = 128\nMAX_PREDS = 1\nTRAIN_VAL_SPLIT = 0.8\nBATCH_SIZE = 8\nHIDDEN_DIM = 16\nLR = 0.0001\nEPOCHS = 100\nOPTIM = 'adam'\nLAMBDA = 0.001\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"id":"KhuSrCtd4BeZ","execution":{"iopub.status.busy":"2021-12-13T17:45:33.241776Z","iopub.execute_input":"2021-12-13T17:45:33.242519Z","iopub.status.idle":"2021-12-13T17:45:33.248185Z","shell.execute_reply.started":"2021-12-13T17:45:33.242481Z","shell.execute_reply":"2021-12-13T17:45:33.247294Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### Data Pre-processing\n\nExtracting frames from video and making it suitable to feed to model","metadata":{"id":"kd_2MbCRfOwq"}},{"cell_type":"code","source":"def crop_center_square(frame):\n  y,x = frame.shape[0:2]\n  min_dim = min(y,x)\n  start_x = (x // 2) - (min_dim // 2)\n  start_y = (y // 2) - (min_dim // 2)\n  return frame[start_y:start_y+min_dim, start_x:start_x+min_dim, :]\n\ndef load_video(path, resize=(IMG_SIZE,IMG_SIZE), max_frames=0, resize_manually=1):\n  cap = cv2.VideoCapture(path)\n  fps = int(cap.get(cv2.cv2.CAP_PROP_FPS))\n  # print(fps)\n  frames = []\n  try:\n    while True:\n      ret, frame = cap.read()\n      if not ret:\n        break\n\n      if resize_manually:\n        frame = crop_center_square(frame)\n        frame = cv2.resize(frame, resize)\n      # trace(frame, 'frame')\n      # frame = frame[:, :, [2,1,0]]  # BGR to RGB\n      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # BGR to GRAY\n      frames.append(frame)\n\n      if len(frames) == max_frames:\n        break\n  finally:\n    cap.release()\n  \n  frames = np.array(frames)\n  frames = np.expand_dims(frames, axis=3)\n\n  return frames","metadata":{"id":"ElNjWyxbfE4r","execution":{"iopub.status.busy":"2021-12-13T17:45:34.240725Z","iopub.execute_input":"2021-12-13T17:45:34.241166Z","iopub.status.idle":"2021-12-13T17:45:34.252076Z","shell.execute_reply.started":"2021-12-13T17:45:34.241127Z","shell.execute_reply":"2021-12-13T17:45:34.251218Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"path = os.path.join(train_path, 'v_CricketShot_g15_c01.avi')\nframes = load_video(path, resize=(IMG_SIZE,IMG_SIZE), max_frames=MAX_FRAMES)\ntrace(frames, 'frames')","metadata":{"id":"4KFOPQ-xfE0V","outputId":"17ac4679-2149-41dc-dd59-017d8a5b7b76","execution":{"iopub.status.busy":"2021-12-13T17:45:34.738733Z","iopub.execute_input":"2021-12-13T17:45:34.738989Z","iopub.status.idle":"2021-12-13T17:45:34.755604Z","shell.execute_reply.started":"2021-12-13T17:45:34.738961Z","shell.execute_reply":"2021-12-13T17:45:34.754764Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"num_cols = 4\nnum_rows = MAX_FRAMES // num_cols\nf, ax = plt.subplots(num_rows, num_cols)\ncomp = 0\n\nfor i in range(num_rows):\n  for j in range(num_cols):\n    comp += 1\n    frame = frames[i*num_cols+j]\n    ax[i,j].imshow(frame[:, :, 0], cmap='gray')\n    ax[i,j].set_title(comp)\n    ax[i,j].axis('off')\n\n  f.set_figheight(15)\n  f.set_figwidth(15)\n\nplt.show()","metadata":{"id":"i_XRzAeOfqVV","outputId":"fc8f6d42-dfe1-4ea1-e019-164d89b57e3e","execution":{"iopub.status.busy":"2021-12-13T17:45:35.283067Z","iopub.execute_input":"2021-12-13T17:45:35.283619Z","iopub.status.idle":"2021-12-13T17:45:36.296489Z","shell.execute_reply.started":"2021-12-13T17:45:35.283585Z","shell.execute_reply":"2021-12-13T17:45:36.293819Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"#### Make Custom Dataset","metadata":{"id":"da08mn3FoFkF"}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n  def __init__(self, dir, video_list, img_size=(IMG_SIZE,IMG_SIZE), max_frames=12, max_preds=1, transform=None):\n    \"\"\"\n      Parameters\n      -----------\n        dir: path to train directory or test directory\n        video_list: contains .avi files in dir\n        img_size: resize frames to image size \n        max_frames: divide video into max number of frames\n        max_preds: number of frames to be predicted\n    \"\"\"\n    self.dir = dir\n    self.video_list = video_list\n    self.img_size = img_size\n    self.max_frames = max_frames\n    self.max_preds = max_preds\n    self.transform = transform\n\n  def __len__(self):\n    return len(self.video_list)\n  \n  def __getitem__(self, index):\n    path = os.path.join(self.dir, self.video_list[index])\n    frames = load_video(path, max_frames=self.max_frames, resize_manually=True, resize=self.img_size)\n\n    input_frames_size = self.max_frames-self.max_preds\n    target_frames_size = self.max_preds\n\n    input_frames = frames[:input_frames_size]\n    target_frames = frames[self.max_frames-self.max_preds:]\n\n    input_frames_tensor = torch.zeros((input_frames_size, 1, self.img_size[0], self.img_size[1]))\n    target_frames_tensor = torch.zeros((target_frames_size, 1, self.img_size[0], self.img_size[1]))\n\n    if self.transform is not None:\n      for f in range(input_frames.shape[0]):\n        input_frames_tensor[f] = self.transform(input_frames[i])\n      for f in range(target_frames.shape[0]):\n        target_frames_tensor[f] = self.transform(target_frames[f])\n      \n    return (input_frames_tensor, target_frames_tensor)","metadata":{"id":"0CqLDdgKoHvh","execution":{"iopub.status.busy":"2021-12-13T17:45:36.298339Z","iopub.execute_input":"2021-12-13T17:45:36.298787Z","iopub.status.idle":"2021-12-13T17:45:36.312824Z","shell.execute_reply.started":"2021-12-13T17:45:36.298751Z","shell.execute_reply":"2021-12-13T17:45:36.311866Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToPILImage(),\n                                transforms.ToTensor(),\n                                ])\n\ntrain_size = int(len(train_files) * TRAIN_VAL_SPLIT)\n\nrandom.shuffle(train_files)\ntrain_videos = train_files[:train_size]\nval_videos = train_files[train_size:]\n\ntrain_dataset = CustomDataset(train_path, train_videos, transform=transform, max_preds=MAX_PREDS, max_frames=MAX_FRAMES)\nval_dataset = CustomDataset(train_path, val_videos, transform=transform, max_preds=MAX_PREDS, max_frames=MAX_FRAMES)\ntest_dataset = CustomDataset(test_path, test_files, transform=transform, max_preds=MAX_PREDS, max_frames=MAX_FRAMES)","metadata":{"id":"T-V9RimfoHsV","execution":{"iopub.status.busy":"2021-12-13T17:45:36.519134Z","iopub.execute_input":"2021-12-13T17:45:36.519885Z","iopub.status.idle":"2021-12-13T17:45:36.527433Z","shell.execute_reply.started":"2021-12-13T17:45:36.519831Z","shell.execute_reply":"2021-12-13T17:45:36.526196Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"x,y = train_dataset[0]\ntrace(x, 'x')\ntrace(y, 'y')\n# Shape of both x and y: (frames, channels, h, w)","metadata":{"id":"OtQM1GqVvmav","outputId":"fb40a78f-7d82-4b50-eb14-e6036518048e","execution":{"iopub.status.busy":"2021-12-13T17:45:36.944433Z","iopub.execute_input":"2021-12-13T17:45:36.944692Z","iopub.status.idle":"2021-12-13T17:45:36.963072Z","shell.execute_reply.started":"2021-12-13T17:45:36.944656Z","shell.execute_reply":"2021-12-13T17:45:36.962359Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\nval_loader = DataLoader(val_dataset, shuffle=True, batch_size=BATCH_SIZE)\ntest_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)\n\nprint('Length of train loader: {}'.format(len(train_loader)))\nprint('Length of val loader: {}'.format(len(val_loader)))\nprint('Length of test loader: {}'.format(len(test_loader)))","metadata":{"id":"8jJYzLdDvWO-","outputId":"9cf81bfd-964c-46f8-ac25-4faf7def3323","execution":{"iopub.status.busy":"2021-12-13T17:45:37.254783Z","iopub.execute_input":"2021-12-13T17:45:37.255033Z","iopub.status.idle":"2021-12-13T17:45:37.262185Z","shell.execute_reply.started":"2021-12-13T17:45:37.255006Z","shell.execute_reply":"2021-12-13T17:45:37.261431Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"x,y = next(iter(train_loader))\ntrace(x, 'x')\ntrace(y, 'y')\n# Shape of both x and y: (batch_size, frames, channels, h, w)","metadata":{"id":"h56SEdj4tigi","outputId":"c2299ea2-6726-45c6-b7c1-121cb074a3ab","execution":{"iopub.status.busy":"2021-12-13T17:45:37.547319Z","iopub.execute_input":"2021-12-13T17:45:37.549441Z","iopub.status.idle":"2021-12-13T17:45:37.635439Z","shell.execute_reply.started":"2021-12-13T17:45:37.549401Z","shell.execute_reply":"2021-12-13T17:45:37.634723Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Building Model","metadata":{"id":"STvokpWIFHgO"}},{"cell_type":"markdown","source":"### ConvLSTM Cell\n\n$i_{t} = \\sigma (W_{xi} * X_{t} + W_{hi} * H_{t-1} + W_{ci} \\circ C_{t-1} + b_{i})$ \\\\\n$f_{t} = \\sigma (W_{xf} * X_{t} + W_{hf} * H_{t-1} + W_{cf} \\circ C_{t-1} + b_{f})$ \\\\\n$C_{t} = f_{t} \\circ C_{t-1} + i_{t} \\circ \\tanh (W_{xc} * X_{t} + W_{hc} * H_{t-1} + b_{c})$ \\\\\n$o_{t} = \\sigma (W_{xo} * X_{t} + W_{ho} * H_{t-1} + W_{co} \\circ C_{t} + b_{o})$ \\\\\n$H_{t} = o_{t} \\circ \\tanh(C_{t})$\n\n","metadata":{"id":"DTlCSqqu5Y3o"}},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n  def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n    super(ConvLSTMCell, self).__init__()\n\n    self.input_dim = input_dim\n    self.hidden_dim = hidden_dim\n\n    self.kernel_size = kernel_size\n    self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n    self.bias = bias\n\n    self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n                          out_channels=4 * self.hidden_dim,\n                          kernel_size=self.kernel_size,\n                          padding=self.padding,\n                          bias=self.bias)\n\n  def forward(self, input_tensor, cur_state):\n    h_cur, c_cur = cur_state\n    # shape of input_tensor: (Batch_size, Channels, Height, Width)\n    # Shape if h_cur: (Batch_size, Hidden_dim, Height, Width)\n    # Shape if c_cur: (Batch_size, Hidden_dim, Height, Width)\n\n    combined = torch.cat([input_tensor, h_cur], dim=1)\n\n    combined_conv = self.conv(combined)\n    cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n    i = torch.sigmoid(cc_i)\n    f = torch.sigmoid(cc_f)\n    o = torch.sigmoid(cc_o)\n    g = torch.tanh(cc_g)\n\n    c_next = f * c_cur + i * g\n    h_next = o * torch.tanh(c_next)\n\n    return h_next, c_next\n\n  def init_hidden(self, batch_size, image_size):\n    height, width = image_size\n    return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n            torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))","metadata":{"id":"2SepRkvk4vC5","execution":{"iopub.status.busy":"2021-12-13T17:45:46.311444Z","iopub.execute_input":"2021-12-13T17:45:46.312216Z","iopub.status.idle":"2021-12-13T17:45:46.324060Z","shell.execute_reply.started":"2021-12-13T17:45:46.312184Z","shell.execute_reply":"2021-12-13T17:45:46.323115Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"convlstm = ConvLSTMCell(input_dim=1, hidden_dim=16, kernel_size=(3,3), bias=True)\n[h,c] = convlstm.init_hidden(batch_size=BATCH_SIZE, image_size=(IMG_SIZE,IMG_SIZE))\nprint('Shape of h: {}\\nShape of c: {}'.format(h.shape, c.shape))","metadata":{"id":"kO7ur3C985lQ","outputId":"20cb93db-55b6-4480-846f-5f9d2c4165c9","execution":{"iopub.status.busy":"2021-12-13T17:45:46.701573Z","iopub.execute_input":"2021-12-13T17:45:46.701825Z","iopub.status.idle":"2021-12-13T17:45:46.710924Z","shell.execute_reply.started":"2021-12-13T17:45:46.701795Z","shell.execute_reply":"2021-12-13T17:45:46.710028Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"### Seq2Seq Model with ConvLSTM\n\n![seq2seq](https://user-images.githubusercontent.com/26361028/145701163-4de95534-12d0-400d-83c3-6542c7431761.png)\n\nInput sequence is **Given Frames** \\\\\nOutput sequence is **Predicted Frames**\n","metadata":{"id":"FJ6CCho2CvHq"}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n  def __init__(self, in_channels, hidden_dim):\n    super(Seq2Seq, self).__init__()\n    self.encoder_1_convlstm = ConvLSTMCell(input_dim=in_channels, hidden_dim=hidden_dim, kernel_size=(3,3), bias=True)\n    self.encoder_2_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=(3,3), bias=True)\n    self.decoder_1_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=(3,3), bias=True)\n    self.decoder_2_convlstm = ConvLSTMCell(input_dim=hidden_dim, hidden_dim=hidden_dim, kernel_size=(3,3), bias=True)\n\n    # 3D CNN\n    self.decoder_CNN = nn.Conv3d(in_channels=hidden_dim, out_channels=1, kernel_size=(3,3,3), padding=(1,1,1))\n  \n  def forward(self, x, preds=MAX_PREDS):\n    # Shape of x: (Batch_size, Frames, Channels, Height, Width)\n    outputs = []\n\n    batch_size, num_frames, _, h, w = x.shape\n\n    # Initialize hidden states\n    h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=batch_size, image_size=(h,w))\n    h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=batch_size, image_size=(h,w))\n    h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=batch_size, image_size=(h,w))\n    h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=batch_size, image_size=(h,w))\n\n    # Encoder\n    for f in range(num_frames):\n      h_t, c_t = self.encoder_1_convlstm(input_tensor=x[:, f, :, :, :], cur_state=[h_t, c_t])\n      h_t2, c_t2 = self.encoder_2_convlstm(input_tensor=h_t, cur_state=[h_t2, c_t2])\n\n    encoded_vector = h_t2\n\n    # Decoder\n    for _ in range(preds):\n      h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=encoded_vector, cur_state=[h_t3, c_t3])\n      h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t3, cur_state=[h_t4, c_t4])\n\n      # update encoded vector\n      encoded_vector = h_t4\n      outputs.append(h_t4) # Append predictions\n\n    outputs = torch.stack(outputs, 1)\n    outputs = outputs.permute(0,2,1,3,4)\n    outputs = self.decoder_CNN(outputs)\n    outputs = torch.nn.Sigmoid()(outputs)\n    return outputs","metadata":{"id":"AMLOY6xgClev","execution":{"iopub.status.busy":"2021-12-13T17:45:47.482010Z","iopub.execute_input":"2021-12-13T17:45:47.482566Z","iopub.status.idle":"2021-12-13T17:45:47.499029Z","shell.execute_reply.started":"2021-12-13T17:45:47.482529Z","shell.execute_reply":"2021-12-13T17:45:47.498309Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model = Seq2Seq(1, HIDDEN_DIM)\nx = torch.rand((BATCH_SIZE, MAX_FRAMES, 1, IMG_SIZE, IMG_SIZE))\noutputs = model(x, preds=MAX_PREDS)\ntrace(outputs, 'outputs') # (batch_size, output_channels, predicted_frames, h, w)","metadata":{"id":"nn6-av4sHuX4","outputId":"fb228b0f-f8bc-4247-904f-24c7fc713b68","execution":{"iopub.status.busy":"2021-12-13T17:45:55.713891Z","iopub.execute_input":"2021-12-13T17:45:55.714675Z","iopub.status.idle":"2021-12-13T17:45:59.951896Z","shell.execute_reply.started":"2021-12-13T17:45:55.714633Z","shell.execute_reply":"2021-12-13T17:45:59.950748Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### Defining Loss and Optimizer","metadata":{"id":"QE2jmrXujQ6J"}},{"cell_type":"code","source":"model = Seq2Seq(in_channels=1, hidden_dim=HIDDEN_DIM).to(DEVICE)\ncriterion = nn.MSELoss()\n\nif OPTIM == 'sgd':\n  optimizer = optim.SGD(model.parameters(), lr=LR)\nif OPTIM == 'adam':\n  optimizer = optim.Adam(model.parameters(), lr=LR)","metadata":{"id":"Riebm81WjTzf","execution":{"iopub.status.busy":"2021-12-13T17:46:00.643547Z","iopub.execute_input":"2021-12-13T17:46:00.643824Z","iopub.status.idle":"2021-12-13T17:46:00.653402Z","shell.execute_reply.started":"2021-12-13T17:46:00.643792Z","shell.execute_reply":"2021-12-13T17:46:00.652547Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"yX3h3QboGP6P"}},{"cell_type":"code","source":"def train():\n  training_loss = []\n  validation_loss = []\n\n  best_val_loss = np.inf\n\n  for epoch in range(EPOCHS):\n\n    model.train()\n\n    running_loss = 0.0\n\n    for batch_idx, data in enumerate(train_loader):\n      input_frames, target_frames = data\n      input_frames = input_frames.to(DEVICE)\n      target_frames = target_frames.to(DEVICE)\n      \n      predicted_frames = model(input_frames)\n\n      loss = criterion(predicted_frames, target_frames)\n      \n      # MSE with L2 regularizer\n      l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())  \n      loss = loss + LAMBDA * l2_norm\n    \n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n\n      running_loss += loss.item()\n\n    train_loss = running_loss / len(train_loader)\n\n    training_loss.append(train_loss)\n\n    model.eval()\n    with torch.no_grad():\n      running_loss = 0.0\n      for batch_idx, data in enumerate(val_loader):\n        input_frames, target_frames = data\n        input_frames = input_frames.to(DEVICE)\n        target_frames = target_frames.to(DEVICE)\n        \n        predicted_frames = model(input_frames)\n\n        loss = criterion(predicted_frames, target_frames)\n        \n        # MSE with L2 regularizer\n        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())  \n        loss = loss + LAMBDA * l2_norm\n        \n        running_loss += loss.item()\n\n      val_loss = running_loss / len(val_loader)\n      validation_loss.append(val_loss)\n\n    print(f'Epoch: {epoch+1}/{EPOCHS} \\tTrain Loss: {train_loss:.6f}\\tVal Loss: {val_loss:.6f}')\n\n    if val_loss < best_val_loss:\n      best_val_loss = val_loss\n\n      checkpoint = {\n          'state_dict': model.state_dict(),\n          'optimizer': optimizer.state_dict()\n      }\n\n      save_checkpoint(checkpoint)\n\n\n  return training_loss, validation_loss","metadata":{"id":"wIO56bCaR24s","execution":{"iopub.status.busy":"2021-12-13T17:46:01.338731Z","iopub.execute_input":"2021-12-13T17:46:01.339466Z","iopub.status.idle":"2021-12-13T17:46:01.351379Z","shell.execute_reply.started":"2021-12-13T17:46:01.339425Z","shell.execute_reply":"2021-12-13T17:46:01.350431Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = train()","metadata":{"id":"73JL-UbyGUfB","outputId":"b67de7ee-5afc-48fd-939b-2919b2174427","execution":{"iopub.status.busy":"2021-12-13T17:46:01.536678Z","iopub.execute_input":"2021-12-13T17:46:01.536931Z","iopub.status.idle":"2021-12-13T17:47:53.800573Z","shell.execute_reply.started":"2021-12-13T17:46:01.536901Z","shell.execute_reply":"2021-12-13T17:47:53.799747Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"plot_loss(train_loss, val_loss, save_fig=True)","metadata":{"id":"nBl_gy8my2Bc","outputId":"7645e118-98db-4c8d-84aa-a9d510082dfb","execution":{"iopub.status.busy":"2021-12-13T17:47:53.802124Z","iopub.execute_input":"2021-12-13T17:47:53.802546Z","iopub.status.idle":"2021-12-13T17:47:54.072662Z","shell.execute_reply.started":"2021-12-13T17:47:53.802506Z","shell.execute_reply":"2021-12-13T17:47:54.071936Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{"id":"g1ELGVhiGS-5"}},{"cell_type":"code","source":"# Load best model\nload_checkpoint(torch.load('my_checkpoint.pth.tar'), model, optimizer)","metadata":{"id":"PthriRshGT7H","outputId":"32a069e0-f0bc-42d0-af52-94257dcfbf8b","execution":{"iopub.status.busy":"2021-12-13T17:47:59.934203Z","iopub.execute_input":"2021-12-13T17:47:59.934696Z","iopub.status.idle":"2021-12-13T17:47:59.948318Z","shell.execute_reply.started":"2021-12-13T17:47:59.934655Z","shell.execute_reply":"2021-12-13T17:47:59.947558Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def test():\n  true_frames = []  # batch_wise\n  pred_frames = []   # batch_wise\n  model.eval()\n  with torch.no_grad():\n    running_loss = 0.0\n    for batch_idx, data in enumerate(test_loader):\n      input_frames, target_frames = data\n      input_frames = input_frames.to(DEVICE)\n      target_frames = target_frames.to(DEVICE)\n\n      predicted_frames = model(input_frames)  # upto max predictions (default 1 frame prediction)\n\n      loss = criterion(predicted_frames, target_frames)\n\n      running_loss += loss.item()\n\n      true_frames.append(target_frames)\n      pred_frames.append(predicted_frames)\n\n    test_loss = running_loss / len(test_loader)\n\n    true_frames = torch.cat(true_frames, dim=0)\n    predicted_frames = torch.cat(pred_frames, dim=0)\n\n  return test_loss, true_frames, predicted_frames","metadata":{"id":"JuRSHmEyzhbe","execution":{"iopub.status.busy":"2021-12-13T17:48:01.049329Z","iopub.execute_input":"2021-12-13T17:48:01.050114Z","iopub.status.idle":"2021-12-13T17:48:01.057603Z","shell.execute_reply.started":"2021-12-13T17:48:01.050062Z","shell.execute_reply":"2021-12-13T17:48:01.056795Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test_loss, true_frames, predicted_frames = test()\nprint(f'Loss obtained on test dataset: {test_loss}')\n\ntrue_frames = true_frames.squeeze(1)\npredicted_frames = predicted_frames.squeeze(1)\n\ntrue_frames = true_frames.cpu().numpy()\npredicted_frames = predicted_frames.cpu().numpy()","metadata":{"id":"dSsVvdWrlMiZ","outputId":"5ef7af90-1e5e-4678-d2e1-b92ff72a069a","execution":{"iopub.status.busy":"2021-12-13T17:48:01.672421Z","iopub.execute_input":"2021-12-13T17:48:01.672680Z","iopub.status.idle":"2021-12-13T17:48:05.642880Z","shell.execute_reply.started":"2021-12-13T17:48:01.672652Z","shell.execute_reply":"2021-12-13T17:48:05.641425Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Compute SSIM similarity scores","metadata":{"id":"EE45kb83pZXg"}},{"cell_type":"code","source":"def compute_ssim(true_frames, predicted_frames, score_k=1):\n  ssim_score = []\n  for b in range(true_frames.shape[0]):\n    kth_true_frame = true_frames[b][score_k-1]\n    kth_predicted_frame = predicted_frames[b][score_k-1]\n\n    score, _ = ssim(kth_true_frame, kth_predicted_frame, full=True)\n    ssim_score.append(score)\n  \n  avg_ssim_score = np.mean(ssim_score)    # average ssim score across test data\n  min_ssim_score = np.min(ssim_score)     # minimum ssim score across test data\n  max_ssim_score = np.max(ssim_score)     # maximum ssim score across test data\n\n  return avg_ssim_score, min_ssim_score, max_ssim_score","metadata":{"id":"epQJCfUdnSt-","execution":{"iopub.status.busy":"2021-12-13T17:48:05.644567Z","iopub.execute_input":"2021-12-13T17:48:05.644895Z","iopub.status.idle":"2021-12-13T17:48:05.650906Z","shell.execute_reply.started":"2021-12-13T17:48:05.644856Z","shell.execute_reply":"2021-12-13T17:48:05.650117Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"avg_ssim_score, min_ssim_score, max_ssim_score = compute_ssim(true_frames, predicted_frames)\nprint(f'Average ssim score: {avg_ssim_score}')\nprint(f'Minimum ssim score: {min_ssim_score}')\nprint(f'Maximum ssim score: {max_ssim_score}')","metadata":{"id":"qbcvtdnMqAVu","outputId":"2b9839d9-6f3b-40af-ca94-217c7341f235","execution":{"iopub.status.busy":"2021-12-13T17:48:05.651953Z","iopub.execute_input":"2021-12-13T17:48:05.652456Z","iopub.status.idle":"2021-12-13T17:48:05.915293Z","shell.execute_reply.started":"2021-12-13T17:48:05.652418Z","shell.execute_reply":"2021-12-13T17:48:05.914458Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Predicted frames","metadata":{"id":"kTZAIozGueZj"}},{"cell_type":"code","source":"def visualize_predicted_frames(true_frames, predicted_frames, visualize=20, k=1, title='none',figname='none'):\n  frame_indices = np.arange(true_frames.shape[0])\n  random.shuffle(frame_indices)\n  frame_indices = frame_indices[:visualize]\n\n  num_rows = 2\n  num_cols = visualize\n\n  f, ax = plt.subplots(num_rows, num_cols)\n  comp = 0\n\n  for i in range(visualize):\n    idx = frame_indices[i]\n    true_frame = true_frames[idx][k-1]\n    predicted_frame = predicted_frames[idx][k-1]\n    \n    ax[0,i].imshow(true_frame, cmap='gray')\n    ax[0,i].set_title('True Frame')\n    ax[0,i].axis('off')\n\n    ax[1,i].imshow(predicted_frame, cmap='gray')\n    ax[1,i].set_title('Predicted Frame')\n    ax[1,i].axis('off')\n\n    f.set_figheight(6)\n    f.set_figwidth(15)\n  \n  f.suptitle(title, fontsize=16)\n  plt.savefig(f'{figname}.png')\n  plt.show()","metadata":{"id":"g0PvgstIz9nP","execution":{"iopub.status.busy":"2021-12-13T17:48:18.285662Z","iopub.execute_input":"2021-12-13T17:48:18.285917Z","iopub.status.idle":"2021-12-13T17:48:18.295218Z","shell.execute_reply.started":"2021-12-13T17:48:18.285887Z","shell.execute_reply":"2021-12-13T17:48:18.294381Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"title = 'First frame predictions'\nfigname = 'first_frame'\nvisualize_predicted_frames(true_frames, predicted_frames, visualize=5, k=1, title=title, figname=figname)","metadata":{"id":"vylOmRl60J7n","outputId":"2bb9c3ec-3026-434c-84bf-3004ed0a19ec","execution":{"iopub.status.busy":"2021-12-13T17:48:18.865702Z","iopub.execute_input":"2021-12-13T17:48:18.866234Z","iopub.status.idle":"2021-12-13T17:48:19.667481Z","shell.execute_reply.started":"2021-12-13T17:48:18.866194Z","shell.execute_reply":"2021-12-13T17:48:19.666797Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}